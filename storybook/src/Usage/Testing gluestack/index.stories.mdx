import { Canvas, Meta, Story } from "@storybook/addon-docs";

<Meta title="Usage/Testing gluestack" />

![animation.gif](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5a76e7f3-1082-4379-872d-719114560fb8/animation.gif)

<aside>
ðŸ’¡ **Why Test?**

Automated tests help you and your team build complex gluestack applications quickly and confidently by preventing regressions and encouraging you to break apart your application into testable functions, modules, classes, and components. As with any application, your new gluestack app can fail in many ways, and it's essential that you can catch these issues and fix them before releasing them.

This guide will cover basic terminology and provide recommendations on which tools to choose for your gluestack application.

</aside>

## **When to Test**

Start testing early! We recommend you begin writing tests as soon as you can. The longer you wait to add tests to your application, the more dependencies your application will have, and the harder it will be to start.\*\*\*\*

## **Testing Types**

When designing your glue application's testing strategy, you should leverage the following testing types:

1. **Unit:**
   - Checks that inputs to a given function, class, or composable are producing the expected output or side effects.
2. **Component:**
   - Checks that your component mounts, renders, can be interacted with, and behaves as expected. These tests import more code than unit tests, are more complex, and require more time to execute.
3. **Integration:**
   - Here units or individual components are tested in a group. The focus of the integration testing level is to expose defects at the time of interaction between integrated components or units.
4. **End-to-end**:
   - Checks features that span multiple pages and make real network requests against your production-built gluestack application. These tests often involve standing up a database or other back-end.

Each testing type plays a role in your application's testing strategy and each will protect you against different types of issues.

## Overview

We will briefly discuss what each of these is, how they can be implemented for gluestack applications, and provide some general recommendations.

## Unit Testing

Unit tests are written to verify that small, isolated units of code are working as expected. A unit test usually covers a single function, class, composable, or module. Unit tests focus on logical correctness and only concern themselves with a small portion of the application's overall functionality. They may mock large parts of your application's environment (e.g. initial state, complex classes, 3rd party modules, and network requests).

In general, unit tests will catch issues with a function's business logic and logical correctness.

Take for example thisÂ `increment`Â function:

```jsx
// helpers.js
export function increment(current, max = 10) {
  if (current < max) {
    return current + 1;
  }
  return current;
}
```

Because it's very self-contained, it'll be easy to invoke the increment function and assert that it returns what it's supposed to, so we'll write a Unit Test.

If any of these assertions fail, it's clear that the issue is contained within theÂ `increment`Â function.

```jsx
// helpers.spec.js
import { increment } from "./helpers";

describe("increment", () => {
  test("increments the current number by 1", () => {
    expect(increment(0, 10)).toBe(1);
  });

  test("does not increment the current number over the max", () => {
    expect(increment(10, 10)).toBe(10);
  });

  test("has a default max of 10", () => {
    expect(increment(10)).toBe(10);
  });
});
```

As mentioned previously, unit testing is typically applied to self-contained business logic, components, classes, modules, or functions that do not involve UI rendering, network requests, or other environmental concerns.

These are typically plain JavaScript / TypeScript modules unrelated to gluestack. In general, writing unit tests for business logic in gluestack applications does not differ significantly from applications using other frameworks.

There are two instances where you DO unit test gluestack-specific features:

1. Composables
2. Components

### Composables

One category of functions specific to gluestack applications isÂ Composables, which may require special handling during tests. SeeÂ Testing ComposablesÂ below for more details.

### Unit Testing Components

A component can be tested in two ways:

1. **Whitebox**: (**Unit Testing)**

   Tests that are "Whitebox tests" are aware of the implementation details and dependencies of a component. They are focused onÂ **isolating**Â the component under test. These tests will usually involve mocking some, if not all of your component's children, as well as setting up plugin state and dependencies.

2. **Blackbox**: (**Component Testing)**

   Tests that are "Blackbox tests" are unaware of the implementation details of a component. These tests mock as little as possible to test the integration of your component and the entire system. They usually render all child components and are considered more of an "integration test". See theÂ Component Testing recommendationsÂ below.

### **Recommendation**

[**Jest**](https://jestjs.io/)Â is a popular unit testing framework, and can be made to work with gluestack via its testÂ package.

## Component Testing

In gluestack applications, components are the main building blocks of the UI. Components are therefore the natural unit of isolation when it comes to validating your application's behavior. From a granularity perspective, component testing sits somewhere above unit testing and can be considered a form of integration testing. Much of your gluestack Application should be covered by a component test and we recommend that each gluestack component has its own spec file.

Component tests should catch issues relating to your component's props, events, slots that it provides, styles, classes, lifecycle hooks, and more.

Component tests should not mock child components, but instead, test the interactions between your component and its children by interacting with the components as a user would. For example, a component test should click on an element like a user would instead of programmatically interacting with the component.

Component tests should focus on the component's public interfaces rather than internal implementation details. For most components, the public interface is limited to events emitted, props, and slots. When testing, remember toÂ **test what a component does, not how it does it**.

**DO**

- ForÂ **Visual**Â logic: assert correct render output based on inputted props and slots.
- ForÂ **Behavioral**Â logic: assert correct render updates or emitted events in response to user input events.
  In the below example, we demonstrate a Stepper component that has a DOM element labeled "increment" and can be clicked. We pass a prop calledÂ `max`Â that prevents the Stepper from being incremented pastÂ `2`, so if we click the button 3 times, the UI should still sayÂ `2`.
  We know nothing about the implementation of Stepper, only that the "input" is theÂ `max`Â prop and the "output" is the state of the DOM as the user will see it.

```jsx
const { getByText } = render(Stepper, {
  props: {
    max: 1,
  },
});

getByText("0"); // Implicit assertion that "0" is within the component

const button = getByText("increment");

// Dispatch a click event to our increment button.
await fireEvent.click(button);

getByText("1");

await fireEvent.click(button);
```

```jsx
const valueSelector = "[data-testid=stepper-value]";
const buttonSelector = "[data-testid=increment]";

const wrapper = mount(Stepper, {
  props: {
    max: 1,
  },
});

expect(wrapper.find(valueSelector).text()).toContain("0");

await wrapper.find(buttonSelector).trigger("click");

expect(wrapper.find(valueSelector).text()).toContain("1");
```

```jsx
const valueSelector = "[data-testid=stepper-value]";
const buttonSelector = "[data-testid=increment]";

mount(Stepper, {
  props: {
    max: 1,
  },
});

cy.get(valueSelector)
  .should("be.visible")
  .and("contain.text", "0")
  .get(buttonSelector)
  .click()
  .get(valueSelector)
  .should("contain.text", "1");
```

**DON'T**

Don't assert the private state of a component instance or test the private methods of a component. Testing implementation details make the tests brittle, as they are more likely to break and require updates when the implementation changes.

The component's ultimate job is rendering the correct DOM output, so tests focusing on the DOM output provide the same level of correctness assurance (if not more) while being more robust and resilient to change.

Don't rely exclusively on snapshot tests. Asserting HTML strings does not describe correctness. Write tests with intentionality.

If a method needs to be tested thoroughly, consider extracting it into a standalone utility function and writing a dedicated unit test for it. If it cannot be extracted cleanly, it may be tested as a part of a component, integration, or end-to-end test that covers it.

### **Recommendation**

[**Cypress Component Testing**](https://on.cypress.io/component)Â for components whose expected behavior depends on properly rendering styles or triggering native DOM events. Can be used with Testing Library viaÂ [@testing-library/cypress](https://testing-library.com/docs/cypress-testing-library/intro).

## Integration **Testing**

You can useÂ `create-next-app`Â with theÂ [with-cypress example](https://github.com/vercel/next.js/tree/canary/examples/with-cypress)Â to quickly get started.

```bash
npx create-next-app@latest --example with-cypress with-cypress-app
```

### **[Manual setup](https://nextjs.org/docs/testing#manual-setup)**

To get started with Cypress, install theÂ `cypress`Â package:

```bash
npm install --save-dev cypress
```

Add Cypress to theÂ `package.json`Â scripts field:

```json
"scripts": {
  "dev": "next dev",
  "build": "next build",
  "start": "next start",
  "cypress": "cypress open",
}
```

Run Cypress for the first time to generate examples that use their recommended folder structure:

```bash
npm run cypress
```

You can look through the generated examples and theÂ [Writing Your First Test](https://docs.cypress.io/guides/getting-started/writing-your-first-test)Â section of the Cypress Documentation to help you get familiar with Cypress.

### **[Creating your first Cypress integration test](https://nextjs.org/docs/testing#creating-your-first-cypress-integration-test)**

Assuming the following two Next.js pages:

```jsx
// pages/index.js
import Link from "next/link";

export default function Home() {
  return (
    <nav>
      <Link href="/about">About</Link>
    </nav>
  );
}
```

```jsx
// pages/about.js
export default function About() {
  return (
    <div>
      <h1>About Page</h1>
    </div>
  );
}
```

Add a test to check your navigation is working correctly:

```jsx
// cypress/integration/app.spec.js

describe("Navigation", () => {
  it("should navigate to the about page", () => {
    // Start from the index page
    cy.visit("http://localhost:3000/");

    // Find a link with an href attribute containing "about" and click it
    cy.get('a[href*="about"]').click();

    // The new url should include "/about"
    cy.url().should("include", "/about");

    // The new page should contain an h1 with "About page"
    cy.get("h1").contains("About Page");
  });
});
```

You can useÂ `cy.visit("/")`Â instead ofÂ `cy.visit("http://localhost:3000/")`Â if you addÂ `baseUrl: 'http://localhost:3000'`Â to theÂ `cypress.config.js`Â configuration file.

### **[Running your Cypress tests](https://nextjs.org/docs/testing#running-your-cypress-tests)**

Since Cypress is testing a real Next.js application, it requires the Next.js server to be running prior to starting Cypress. We recommend running your tests against your production code to more closely resemble how your application will behave.

RunÂ `npm run build`Â andÂ `npm run start`, then runÂ `npm run cypress`Â in another terminal window to start Cypress.

> Note:Â Alternatively, you can install theÂ start-server-and-testÂ package and add it to theÂ package.jsonÂ scripts field:Â "test": "start-server-and-test start http://localhost:3000 cypress"Â to start the Next.js production server in conjunction with Cypress. Remember to rebuild your application after new changes.

### **[Getting ready for Continuous Integration (CI)](https://nextjs.org/docs/testing#getting-ready-for-continuous-integration-ci)**

You will have noticed that running Cypress so far has opened an interactive browser which is not ideal for CI environments. You can also run Cypress headlessly using theÂ `cypress run`Â command:

```json
// package.json

"scripts": {
  //...
  "cypress": "cypress open",
  "cypress:headless": "cypress run",
  "e2e": "start-server-and-test start http://localhost:3000 cypress",
  "e2e:headless": "start-server-and-test start http://localhost:3000 cypress:headless"
}
```

## **E2E Testing**

While unit tests provide developers with some degree of confidence, unit and component tests are limited in their abilities to provide holistic coverage of an application when deployed to production. As a result, end-to-end (E2E) tests provide coverage on what is arguably the most important aspect of an application: what happens when users actually use your applications.

End-to-end tests focus on multi-page application behavior that makes network requests against your production-built gluestack application. They often involve standing up a database or other backend and may even be run against a live staging environment.

End-to-end tests will often catch issues with your router, state management library, top-level components (e.g. an App or Layout), public assets, or any request handling. As stated above, they catch critical issues that may be impossible to catch with unit tests or component tests.

End-to-end tests do not import any of your gluestack application's code, but instead, rely completely on testing your application by navigating through entire pages in a real browser.

End-to-end tests validate many of the layers in your application. They can either target your locally built application or even a live Staging environment. Testing against your Staging environment not only includes your frontend code and static server but all associated backend services and infrastructure.

By testing how user actions impact your application, E2E tests are often the key to higher confidence in whether an application is functioning properly or not.

### Choosing an E2E Testing Solution

While end-to-end (E2E) testing on the web has gained a negative reputation for unreliable (flaky) tests and slowing down development processes, modern E2E tools have made strides forward to create more reliable, interactive, and useful tests. When choosing an E2E testing framework, the following sections provide some guidance on things to keep in mind when choosing a testing framework for your application.

### Cross-browser testing

One of the primary benefits that end-to-end (E2E) testing is known for is its ability to test your application across multiple browsers. While it may seem desirable to have 100% cross-browser coverage, it is important to note that cross-browser testing has diminishing returns on a team's resources due to the additional time and machine power required to run them consistently. As a result, it is important to be mindful of this trade-off when choosing the amount of cross-browser testing your application needs.

### Faster feedback loops

One of the primary problems with end-to-end (E2E) tests and development is that running the entire suite takes a long time. Typically, this is only done in continuous integration and deployment (CI/CD) pipelines. Modern E2E testing frameworks have helped to solve this by adding features like parallelization, which allows for CI/CD pipelines to often run magnitudes faster than before. In addition, when developing locally, the ability to selectively run a single test for the page you are working on while also providing hot reloading of tests can help to boost a developer's workflow and productivity.

### First-class debugging experience

While developers have traditionally relied on scanning logs in a terminal window to help determine what went wrong in a test, modern end-to-end (E2E) test frameworks allow developers to leverage tools that they are already familiar with, e.g. browser developer tools.

### Visibility in headless mode

When end-to-end (E2E) tests are run in continuous integration/deployment pipelines, they are often run in headless browsers (i.e., no visible browser is opened for the user to watch). A critical feature of modern E2E testing frameworks is the ability to see snapshots and/or videos of the application during testing, providing some insight into why errors are happening. Historically, it was tedious to maintain these integrations.

### Recommendation

- [Cypress](https://www.cypress.io/)
  Overall, we believe Cypress provides the most complete E2E solution with features like an informative graphical interface, excellent debuggability, built-in assertions and stubs, flake resistance, parallelization, and snapshots. As mentioned above, it also provides support forÂ [Component Testing](https://docs.cypress.io/guides/component-testing/introduction). However, it only supports Chromium-based browsers and Firefox.
- [Playwright](https://playwright.dev/)

Playwrite is also a great E2E testing solution with a wider range of browser support (mainly WebKit). SeeÂ [Why Playwright](https://playwright.dev/docs/why-playwright)Â for more details.

Playwright is a testing framework that lets you automate Chromium, Firefox, and WebKit with a single API.

### **Quickstart**

The fastest way to get started is to useÂ `create-next-app`Â with theÂ [with-playwright example](https://github.com/vercel/next.js/tree/canary/examples/with-playwright). This will create a Next.js project complete with Playwright all set up.

```bash
npx create-next-app@latest --example with-playwright with-playwright-app
```

### **Manual setup**

You can also useÂ `npm init playwright`Â to add Playwright to an existingÂ `NPM`Â project.

To manually get started with Playwright, install theÂ `@playwright/test`Â package:

```bash
npm install --save-dev @playwright/test
```

Add Playwright to theÂ `package.json`Â scripts field:

```jsx
"scripts": {
  "dev": "next dev",
  "build": "next build",
  "start": "next start",
  "test:e2e": "playwright test",
}
```

### **Creating your first Playwright end-to-end test**

Assuming the following two Next.js pages:

```jsx
// pages/index.js
import Link from "next/link";

export default function Home() {
  return (
    <nav>
      <Link href="/about">About</Link>
    </nav>
  );
}
```

```jsx
// pages/about.js
export default function About() {
  return (
    <div>
      <h1>About Page</h1>
    </div>
  );
}
```

Add a test to verify that your navigation is working correctly:

```jsx
// e2e/example.spec.ts

import { test, expect } from "@playwright/test";

test("should navigate to the about page", async ({ page }) => {
  // Start from the index page (the baseURL is set via the webServer in the playwright.config.ts)
  await page.goto("http://localhost:3000/");
  // Find an element with the text 'About Page' and click on it
  await page.click("text=About");
  // The new URL should be "/about" (baseURL is used there)
  await expect(page).toHaveURL("http://localhost:3000/about");
  // The new page should contain an h1 with "About Page"
  await expect(page.locator("h1")).toContainText("About Page");
});
```

You can useÂ `page.goto("/")`Â instead ofÂ `page.goto("http://localhost:3000/")`, if you addÂ `["baseURL": "http://localhost:3000"](https://playwright.dev/docs/api/class-testoptions#test-options-base-url)`Â to theÂ `playwright.config.ts`Â configuration file.

### **Running your Playwright tests**

Since Playwright is testing a real Next.js application, it requires the Next.js server to be running prior to starting Playwright. It is recommended to run your tests against your production code to more closely resemble how your application will behave.

RunÂ `npm run build`Â andÂ `npm run start`, then runÂ `npm run test:e2e`Â in another terminal window to run the Playwright tests.

> Note:Â Alternatively, you can use theÂ web serverÂ feature to let Playwright start the development server and wait until it's fully available.

### **Running Playwright on Continuous Integration (CI)**

Playwright will by default run your tests in theÂ [headless mode](https://playwright.dev/docs/ci#running-headed). To install all the Playwright dependencies, runÂ `npx playwright install-deps`.

## **Testing GraphQL**

You can follow the below example to write test scripts for GraphQL

1. Identify the GraphQL queries, mutations, and subscriptions that you want to test.
2. Write test cases for each query, mutation, and subscription, using a tool such as Jest or Mocha.
3. For each test case, define the input data (if any) and the expected output.
4. Use a GraphQL client library, such as Apollo Client or graphql-request, to execute the GraphQL operations in your test cases.
5. Use assertions to verify that the actual results of the GraphQL operations match the expected results.

Here's an example of a test case written in Jest that tests a GraphQL query:

```jsx
test('Query should return a list of users', async () => {
// Define the input data for the query
		const variables = {
					limit: 2
};

// Define the expected output of the query
const expectedResult = {
			data: {
					users: [
										{
												id: '1',
												name: 'Alice'
										},
										{
												id: '2',
												name: 'Bob'
											}
									]
						}
};

// Execute the query using a GraphQL client
const result = await client.query({
						query: gql
							query GetUsers($limit: Int!) {
													 users(limit: $limit) {
																										  id
																									    name
																								 }
																					 }    ,
						variables
});

// Verify that the actual result matches the expected result
expect(result).toEqual(expectedResult);

});
```

## **Testing Storybook**

Storybook is a popular tool for building and testing user interface components in isolation.

To test your components in Storybook, you can follow these steps:

1. Install and configure Storybook in your project. You can find instructions for doing this in the Storybook documentation.
2. Create a story for each of your components. A story is a single state of a component, and it typically includes the source code for the component and any props that need to be passed to it.
3. Add test cases for each story. You can use a testing library, such as Jest or Mocha, to write test cases that verify the behavior of your components.
4. Run your test cases using the Storybook command-line interface (CLI). You can do this by running the **`storybook test`** command in your terminal.

**Here's an example of a test case written in Jest that tests a component in Storybook:**

```jsx
import { render } from "@testing-library/react";
import MyComponent from "./MyComponent";

test("MyComponent should render correctly", () => {
  const { container } = render(<MyComponent />);
  expect(container).toMatchSnapshot();
});
```

There are many potential test cases that you might want to consider when testing your components in Storybook. Here are a few examples:

1. Verify that your components are rendering correctly. You can test this by using a testing library, such as Jest or Mocha, to render each component and verify that it appears as expected.
2. Test the behavior of your components when they receive different props. You can do this by passing different props to your components and verifying that they behave as expected.
3. Test the interaction between your components and other parts of your application. You can do this by using the Storybook API to simulate events, such as clicks or form submissions, and verify that the expected results are produced.
4. Test the integration between your components and other libraries or frameworks. You can do this by using the Storybook API to import and use these libraries or frameworks, and verifying that they work as expected.
5. Test the compatibility of your components with different browsers and devices. You can do this by using the Storybook API to test your components in different browsers and devices, and verifying that they work as expected.

## **Testing Dapr**

Dapr is a distributed application runtime that simplifies the development of microservices and other distributed systems. To test a Dapr-based application, you can follow these steps:

1. Install and set up Dapr in your development environment. You can find instructions for doing this in the Dapr documentation.
2. Write test cases for your Dapr-based application using a testing library such as Jest or Mocha.
3. In your test cases, use the Dapr HTTP API or the Dapr client libraries to interact with Dapr and the various components in your application.
4. Use assertions to verify that the actual results of the Dapr operations match the expected results.

**Here's an example of a test case written in Jest that tests a Dapr-based application:**

```jsx
import { DaprClient } from "dapr";

test("Dapr should be able to save and retrieve a state", async () => {
  // Create a Dapr client
  const client = new DaprClient({
    logger: console,
  });

  // Save a state value
  await client.saveState({
    storeName: "statestore",
    key: "key1",
    value: {
      data: "value1",
    },
  });

  // Retrieve the saved state value
  const result = await client.getState({
    storeName: "statestore",
    key: "key1",
  });

  // Verify that the retrieved value is correct
  expect(result.data).toEqual({ data: "value1" });
});
```

There are many potential test cases that you might want to consider when testing a Dapr-based application. Here are a few examples:

1. Verify that Dapr is able to save and retrieve state data correctly. You can test this by saving a state value, then retrieving it and verifying that the retrieved value is correct.
2. Test the integration between Dapr and various cloud-native services, such as databases, message brokers, and caching systems. You can do this by using the Dapr client libraries to interact with these services and verify that the expected results are returned.
3. Test the functionality of Dapr's actor model, which allows you to build stateful microservices using an actor-based programming model. You can do this by creating actor instances, invoking actor methods, and verifying the results.
4. Test the integration between Dapr and various programming languages and frameworks. You can do this by using the Dapr client libraries in different languages and frameworks, and verifying that you can successfully invoke Dapr operations.
5. Test the integration between Dapr and various deployment environments, such as Kubernetes, Docker, and Azure Functions. You can do this by deploying your Dapr-based application to these environments and verifying that it works as expected.

## **Testing Hasura**

Hasura is an open-source engine that provides real-time GraphQL APIs on top of a PostgreSQL database. To test a Hasura-based application, you can follow these steps:

1. Install and set up Hasura in your development environment. You can find instructions for doing this in the Hasura documentation.
2. Write test cases for your Hasura-based application using a testing library such as Jest or Mocha.
3. In your test cases, use a GraphQL client library, such as Apollo Client or graphql-request, to execute GraphQL operations against the Hasura GraphQL API.
4. Use assertions to verify that the actual results of the GraphQL operations match the expected results.

Here's an example of a test case written in Jest that tests a Hasura-based application:

```jsx
import { GraphQLClient } from "graphql-request";

test("Hasura should be able to create and retrieve a user", async () => {
  // Create a GraphQL client
  const client = new GraphQLClient("http://localhost:8080/v1/graphql");

  // Execute a mutation to create a user
  const createUserMutation = `
    mutation CreateUser($name: String!) {
      insert_users(objects: {name: $name}) {
        returning {
          id
          name
        }
      }
    }
  `;
  const variables = {
    name: "Alice",
  };
  const createUserResult = await client.request(createUserMutation, variables);
  const userId = createUserResult.insert_users.returning[0].id;

  // Execute a query to retrieve the created user
  const getUserQuery = `
    query GetUser($id: uuid!) {
      users(where: {id: {_eq: $id}}) {
        id
        name
      }
    }
  `;
  const getUserResult = await client.request(getUserQuery, { id: userId });
  const user = getUserResult.users[0];

  // Verify that the retrieved user is correct
  expect(user).toEqual({ id: userId, name: "Alice" });
});
```

## **Testing Cron**

Cron is a Unix utility that allows you to schedule tasks to be executed automatically at a specified time or interval. To test a cron-based application, you can follow these steps:

1. Write test cases for your cron-based application using a testing library such as Jest or Mocha.
2. In your test cases, use the **`cron`** library or another similar library to simulate the execution of your cron tasks.
3. Use assertions to verify that the tasks are executed as expected, including verifying that the correct input data is passed to the tasks and that the expected output is produced.

Here's an example of a test case written in Jest that tests a cron-based application:

```jsx
import { CronJob } from "cron";

test("Cron job should execute every minute", () => {
  // Create a mock function to represent the cron task
  const task = jest.fn();

  // Schedule the cron job to run every minute
  const job = new CronJob("* * * * *", task);

  // Start the cron job
  job.start();

  // Wait for the cron job to execute
  setTimeout(() => {
    // Verify that the cron task was called
    expect(task).toHaveBeenCalled();

    // Stop the cron job
    job.stop();
  }, 60000);
});
```

In addition to the above test case, you may also want to consider testing the following aspects of your cron-based application:

- The execution of tasks at specific times or intervals
- The handling of errors in your cron tasks
- The integration of your cron tasks with other parts of your application, such as databases or external APIs
- The compatibility of your cron tasks with different environments, such as local development, staging, and production
